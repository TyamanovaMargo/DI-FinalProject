from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium import webdriver
import time
import pandas as pd
import re

# Setup Chrome options
chrome_options = Options()
chrome_options.add_argument("--headless")  # run in background
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")

# Setup Chrome driver (make sure you have chromedriver installed)
# service = Service('/path/to/chromedriver')  # <<<--- REPLACE with your path
driver = webdriver.Chrome()

def smart_scroll(driver, pause_time=1):
        last_height = driver.execute_script("return document.body.scrollHeight")  # –°–∫–æ–ª—å–∫–æ —Å–µ–π—á–∞—Å –≤—Å—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö

        while True:
            # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º –≤–Ω–∏–∑ –¥–æ –∫–æ–Ω—Ü–∞
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")

            # –ñ–¥—ë–º, —á—Ç–æ–±—ã —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ–ª–∞ –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            time.sleep(pause_time)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—É—é –≤—ã—Å–æ—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            new_height = driver.execute_script("return document.body.scrollHeight")

            if new_height == last_height:
                # –ï—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –±–æ–ª—å—à–µ –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è ‚Äî –∑–Ω–∞—á–∏—Ç –≤—Å—ë –∑–∞–≥—Ä—É–∂–µ–Ω–æ
                break

            last_height = new_height

def extract_count(parts, parameter):
    
        patterns = {
            1: r'(\d+)\s+◊ó◊ì◊®◊ô◊ù',
            2: r'◊ß◊ï◊û◊î\s+(\d+)',
            3: r'(\d+)\s+◊û◊¥◊®'
        }
        
        if parameter in patterns:
            match = re.search(patterns[parameter], parts)
            if match:
                return match.group(1)
            else:
                return None
        else:
            return None
        
def get_listings(driver):
        listings = driver.find_elements(By.CSS_SELECTOR, "li[data-testid='item-basic'][data-nagish='feed-item-list-box']")
        return listings

# Create an empty list for all ads
data = []

for page_number in range(1, 50):  # –æ—Ç 1 –¥–æ 10 —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    url = f"https://www.yad2.co.il/realestate/forsale?page={page_number}"
    driver.get(url)

    # Wait for listings to load
    WebDriverWait(driver, 5).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "li[data-testid='item-basic'][data-nagish='feed-item-list-box']"))

    )
 

    smart_scroll(driver)
    listings = get_listings(driver)  # Get all listings on the current page
    print(f"Found {len(listings)} listings")

    for listing in listings:
        try:
            address = listing.find_element(By.CLASS_NAME, "item-data-content_heading__tphH4").text

        except:
            address = None

        try:
            price = listing.find_element(By.CLASS_NAME, "item-data-content_priceSlot__yzYXU").text
        except:
            price = None

        try:
            link_element = listing.find_element(By.CLASS_NAME, "item-layout_itemLink__CZZ7w")
            link = link_element.get_attribute("href")
        except:
            link = None
                
        try:
            content = listing.find_element(By.XPATH, './/h2[@data-nagish="content-section-title"]').text
            parts = content.split('‚Ä¢')
            # print(parts)
            area_parts = parts[-1].strip() 
            area_size = extract_count(area_parts,3)
            # print(area)   
            floor_parts = parts[-2].strip()
            floor_count = extract_count(floor_parts,2)

            rooms_parts = parts[-3].strip()
            rooms_count = extract_count(rooms_parts,1)
            
        except:
            link = None
        try:
            property_type = info = listing.find_element(By.XPATH, './/span[contains(@class, "item-data-content_itemInfoLine__AeoPP")]').text
            parts = property_type.split(',')
            property_type = parts[0].strip() if len(parts) > 0 else None
            neighborhood = parts[1].strip() if len(parts) > 1 else None
            city = parts[2].strip() if len(parts) > 2 else None
        except:
            link = None
        try:
            tags_div = listing.find_element(By.CLASS_NAME, "item-tags_itemTagsBox__Uz23E")
            span_tags = tags_div.find_elements(By.TAG_NAME, "span")
            tags_adiitional_info = [span.text.strip() for span in span_tags]
            info1 = tags_adiitional_info[0].strip() if len(tags_adiitional_info) > 0 else None
            info2 = tags_adiitional_info[1].strip() if len(tags_adiitional_info) > 1 else None
            info3 = tags_adiitional_info[2].strip() if len(tags_adiitional_info) > 2 else None
            # print(info1)
        
        except Exception as e:
            print(f"Error: {e}")
        # print({
        #     "Title":address,
        #     "Price": price,
        #     "Link": link,
        #     "Content": content,
        #     "Property Type": property_type,
        #     "City": city,
        #     "Neighborhood": neighborhood
        # })
        # add to the list
        data.append({
            "Address": address,
            "Price": price,
            "Link": link,
            "Property Type": property_type,
            "Rooms_count": rooms_count,
            "Floor": floor_count,
            "Area": area_size,
            "City": city,
            "Neighborhood": neighborhood,
            "Tags1": info1,
            "Tags2": info2,
            "Tags3": info3,
        })
        # üëâ –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –ø–∞—É–∑—É –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
        time.sleep(3)



# –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤ pandas DataFrame
df = pd.DataFrame(data)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
df.to_csv('yad2_listings_fifty.csv', index=False, encoding='utf-8-sig')

print("‚úÖ CSV saved as yad2_listings.csv")
# Close browser
driver.quit()
